{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a655fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras.models import Model\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import pandas\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import time\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Reshape\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "from keras.layers import (LSTM, BatchNormalization, Dense, Dropout, Embedding,\n",
    "                          Input, Lambda, TimeDistributed, GRU, Masking)\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Attention\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import GlobalAveragePooling2D, Permute, Multiply, dot, Dot\n",
    "import random\n",
    "from random import sample\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfbedd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "def create_model():\n",
    "    vocab_size = 5185+1\n",
    "    max_length = 40\n",
    "    unit_size = 512\n",
    "\n",
    "    # image feature extractor model\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(512, activation='relu')(fe1)\n",
    "    fe3 = BatchNormalization()(fe2)\n",
    "    fe4 = Lambda(lambda x : K.expand_dims(x, axis=1))(fe3)\n",
    "\n",
    "    # partial caption sequence model\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 512, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)  \n",
    "\n",
    "    LSTMLayer = LSTM(512, return_state = True, dropout=0.5)\n",
    "\n",
    "    a0 = Input(shape=(unit_size,))\n",
    "    c0 = Input(shape=(unit_size,))\n",
    "\n",
    "    a, b, c = LSTMLayer(fe4, initial_state = [a0, c0])\n",
    "\n",
    "    A,_,_ = LSTMLayer(se2, initial_state=[b,c])\n",
    "\n",
    "    outputs = Dense(vocab_size, activation='softmax')(A)\n",
    "\n",
    "    # merge the two input models\n",
    "    model = Model(inputs=[inputs1, inputs2, a0, c0], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ae6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(X_path, y_in_path, y_out_path, batch_size):\n",
    "    for i in range(0, 2022727, batch_size):\n",
    "        y_out = np.load(y_out_path, mmap_mode=\"r\")[i:i+batch_size]\n",
    "        X = np.load(X_path, mmap_mode=\"r\")[i:i+batch_size]\n",
    "        y_in = np.load(y_in_path, mmap_mode=\"r\")[i:i+batch_size]\n",
    "        \n",
    "        X = np.array(X)\n",
    "        y_in = np.array(y_in)\n",
    "        y_out = np.array(y_out)\n",
    "        \n",
    "        yield [X, y_in, np.zeros(shape=(1024,512)), np.zeros(shape=(1024,512))], y_out\n",
    "        del y_out\n",
    "        del X\n",
    "        del y_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e32ea60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_path, y_in_path, y_out_path, batch_size, start_epoch, end_epoch):\n",
    "    total_num_of_samples = len(np.load(X_path, mmap_mode=\"r\"))\n",
    "    for i in range(start_epoch, end_epoch+1):\n",
    "        g = gen(X_path, y_in_path, y_out_path, batch_size)\n",
    "        print(f\"epoch_{i}\")\n",
    "        model.fit(g, epochs=1, steps_per_epoch=total_num_of_samples//batch_size)\n",
    "        model.save(f\"image_caption_gen_epoch_{i}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba933d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = create_model()\n",
    "    X_path = \"/kaggle/input/30k-dataset/train/X_train.npy\"\n",
    "    y_in_path = \"/kaggle/input/30k-dataset/train/y_in_train.npy\"\n",
    "    y_out_path = \"/kaggle/input/30k-dataset/train/y_out_train.npy\"\n",
    "    batch_size = 1024\n",
    "    start_epoch = 1\n",
    "    end_epoch = 20\n",
    "    train(model, X_path, y_in_path, y_out_path, batch_size, start_epoch, end_epoch )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
