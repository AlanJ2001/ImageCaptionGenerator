{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30965abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "from glob import glob\n",
    "from keras.applications import ResNet50\n",
    "import copy\n",
    "import sys\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import time\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import string\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c27e73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "\n",
    "def resnet():\n",
    "    resnet_model = ResNet50(include_top=True)\n",
    "    resnet_model = Model(inputs=resnet_model.input, outputs=resnet_model.layers[-2].output)\n",
    "    return resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99f12d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the images\n",
    "# generate a dictionary of image filename -> feature vector\n",
    "# start_index is inclusive\n",
    "\n",
    "def generate_feature_vectors(num_of_images, images_path, model):\n",
    "    img_feature_vectors = {}\n",
    "    images = [f for f in os.listdir(images_path) if os.path.isfile(os.path.join(images_path, f)) and f.endswith('.jpg')]\n",
    "    \n",
    "    count = 0\n",
    "    for item in images[:num_of_images]:\n",
    "        img = cv2.imread(images_path+item)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img.reshape(1, 224, 224, 3)\n",
    "\n",
    "        feature_vector = model.predict(img, verbose=0).reshape(2048,)\n",
    "\n",
    "        img_feature_vectors[item] = feature_vector\n",
    "\n",
    "        count += 1\n",
    "\n",
    "        if (count%50==0):\n",
    "            print(count)\n",
    "\n",
    "    return img_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77452d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes a string lowercase, prepends it with the string 'sos' and appends with 'eos'\n",
    "def process_string(s):\n",
    "    s = s.lower()\n",
    "    s = 'sos ' + s + ' eos'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c66cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_captions_dict(captions_path, img_feature_vectors):\n",
    "    df = pd.read_csv(captions_path, delimiter='|')\n",
    "    df.columns = ['image_name', 'comment_number', 'comment']\n",
    "    del df['comment_number']\n",
    "    df['comment'][19999] = ' A dog runs across the grass .'\n",
    "    captions_dict = {}\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        filename = row['image_name']\n",
    "        caption = process_string(row['comment'])\n",
    "        if filename in img_feature_vectors:\n",
    "            if filename not in captions_dict:\n",
    "                captions_dict[filename] = [caption]\n",
    "            else:\n",
    "                captions_dict[filename].append(caption)\n",
    "    return captions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d7bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(captions_dict, n, train):\n",
    "    vocab_freq = {}\n",
    "    vocab_dict = {}\n",
    "    for key, value in captions_dict.items():\n",
    "        if key not in train:\n",
    "            continue\n",
    "        for caption in value:\n",
    "            caption_as_list = caption.split()\n",
    "            for word in caption_as_list:\n",
    "                if word not in vocab_freq:\n",
    "                    vocab_freq[word] = 1\n",
    "                else:\n",
    "                    vocab_freq[word] = vocab_freq[word]+1\n",
    "    words_to_keep = [w for w in vocab_freq if vocab_freq[w] >= n]\n",
    "    \n",
    "    count = 1\n",
    "    for word in words_to_keep:\n",
    "        if word not in vocab_dict:\n",
    "            vocab_dict[word] = count\n",
    "            count+=1\n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b7ff4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(s, vocab):\n",
    "    s_list = s.split()\n",
    "    encoded_string = []\n",
    "    for word in s_list:\n",
    "        if word in vocab:\n",
    "            encoded_string.append(vocab[word])\n",
    "    return encoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61624e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_captions_dict(captions_dict, vocab):\n",
    "    captions_dict_encoded = copy.deepcopy(captions_dict)\n",
    "\n",
    "    for filename, captions in captions_dict_encoded.items():\n",
    "        for i, caption in enumerate(captions):\n",
    "            captions[i] = encode_string(caption, vocab)\n",
    "    return captions_dict_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e202659",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    images_path = 'Flickr_Data/Images/'\n",
    "    captions_path = \"results.csv\"\n",
    "    max_len = 40\n",
    "    images = glob(images_path+'*.jpg')\n",
    "    \n",
    "    resnet_model = resnet()\n",
    "    img_feature_vectors = generate_feature_vectors(8091, images_path, resnet_model)\n",
    "    images = list(img_feature_vectors.keys())\n",
    "    train = set(images[:28605])\n",
    "    test = set(images[28605:31783])\n",
    "    captions_dict = generate_captions_dict(captions_path, img_feature_vectors)\n",
    "    vocab = create_vocab(captions_dict, 10, train)\n",
    "    captions_dict_encoded = encode_captions_dict(captions_dict, vocab)\n",
    "    \n",
    "    np.save('img_feature_vectors.npy', img_feature_vectors)\n",
    "    np.save('captions_dict.npy', captions_dict)\n",
    "    np.save('captions_dict_encoded.npy', captions_dict_encoded)\n",
    "    np.save('vocab.npy', vocab)\n",
    "    np.save(\"train.npy\", train)\n",
    "    np.save(\"test.npy\", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876ab51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
