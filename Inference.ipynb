{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e77bbb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import ResNet50\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "import time\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from math import log, exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db69a9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "370d09d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.918771232417863"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(0.3)+log(0.6)+log(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d42dbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.7147984280919268"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log(0.3)+log(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055c260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_feature_vectors = np.load('img_feature_vectors.npy', allow_pickle='TRUE').item()\n",
    "captions_dict_encoded = np.load('captions_dict_encoded.npy', allow_pickle='TRUE').item()\n",
    "vocab = np.load('vocab.npy', allow_pickle='TRUE').item()\n",
    "# filenames_testing = np.load(\"dev/filenames_dev.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6229361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/image_caption_gen_epoch_6 (2).h5')\n",
    "max_len = 40\n",
    "vocab_inv = {v: k for k, v in vocab.items()}\n",
    "images_path = 'Flickr_Data/Images/'\n",
    "images = glob(images_path+'*.jpg')\n",
    "\n",
    "resnet_model = ResNet50(include_top=True)\n",
    "resnet_model = Model(inputs=resnet_model.input, outputs=resnet_model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0901df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flickr_Data/Images\\\\892340814_bdd61e10a4.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[8003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57010a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(img_feature_vector):\n",
    "    caption = [1]\n",
    "    next_word = None\n",
    "    img_feature_vector = np.array([img_feature_vector])\n",
    "    \n",
    "    while next_word != vocab['eos'] and len(caption) != 40:\n",
    "        output = model.predict([img_feature_vector, pad(caption)], verbose=0)\n",
    "        next_word = np.argsort(output)[0][-1]\n",
    "        caption.append(next_word)\n",
    "        \n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "187597cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img_feature_vector(filepath):\n",
    "    img = cv2.imread(filepath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.reshape(1, 224, 224, 3)\n",
    "    \n",
    "    feature_vector = resnet_model.predict(img, verbose=0).reshape(1, 2048)\n",
    "    \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a24c589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_caption(encoded_caption):\n",
    "    decoded_caption = []\n",
    "    for word in encoded_caption:\n",
    "        if word == 0:\n",
    "            continue\n",
    "        decoded_caption.append(vocab_inv[word])\n",
    "    return \" \".join(decoded_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6675b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_caption_generator(filename, model):\n",
    "    return decode_caption(generate_caption(img_feature_vectors[filename]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac33f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(filepath):\n",
    "    plt.figure()\n",
    "    img = cv2.imread(filepath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f9c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[8000].split(\"\\\\\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29614070",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print(image_caption_generator(images[8000].split(\"\\\\\")[-1], model))\n",
    "\n",
    "time.time()-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d24716",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image('Flickr_Data/Images\\\\'+filename1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3617dca",
   "metadata": {},
   "source": [
    "30 images results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488ffd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "    results = np.load(\"results/results_8k_new_show_and_tell.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0339118",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "# for item in results:\n",
    "#     print(results[item])\n",
    "#     display(Image(filename='file/kaggle/working/'+item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea04725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "for item in results:\n",
    "    print(item)\n",
    "    display(Image(filename='file/kaggle/working/'+results[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3855f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(150,150))\n",
    "  \n",
    "# setting values to rows and column variables\n",
    "rows = 30\n",
    "columns = 1\n",
    "\n",
    "i=1\n",
    "for x,y in results.items():\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(y)\n",
    "    plt.axis('off')\n",
    "    plt.title(x)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4eee3",
   "metadata": {},
   "source": [
    "Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "956c5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(alist):\n",
    "    return np.array([pad_sequences([alist], maxlen=40, truncating='post')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "candidates = []\n",
    "current_nodes = [([1], 1)]\n",
    "current_nodes_copy = current_nodes[:]\n",
    "\n",
    "while current_nodes != []:\n",
    "    current_nodes = []\n",
    "    for x, y in current_nodes_copy:\n",
    "#         print(current_nodes_copy)\n",
    "#         print()\n",
    "        output = model.predict([img_feature_vector, pad(x)], verbose=0)\n",
    "        next_words = np.argsort(output)[0][-k:]\n",
    "        for item in next_words:\n",
    "            new_prob = log(output[0][item])+y\n",
    "            if item == vocab['eos'] or len(x)==40:\n",
    "                candidates.append((x+[item],new_prob))\n",
    "            else:\n",
    "                current_nodes.append((x+[item],new_prob))\n",
    "#             print(x)\n",
    "#             print()\n",
    "#             print((x+[item],new_prob))\n",
    "#             print()\n",
    "    current_nodes_copy = sorted(current_nodes, key=lambda tup:tup[1])[-k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd9ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sorted(candidates, key=lambda tup:tup[1])[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller captions will have a higher combined probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d7bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in a:\n",
    "    print(decode_caption(item[0]), item[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96fb3a",
   "metadata": {},
   "source": [
    "Beam Search 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a75dfd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_img_feature_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15012/1380435066.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg_feature_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_img_feature_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8003\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_img_feature_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8003\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8003\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_img_feature_vector' is not defined"
     ]
    }
   ],
   "source": [
    "img_feature_vector = generate_img_feature_vector(images[8003])\n",
    "fv = generate_img_feature_vector(images[8003])\n",
    "display(Image(filename=images[8003]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "515d13db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(alist):\n",
    "    return np.array([pad_sequences([alist], maxlen=40, truncating='post')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ebec706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(fv, model, beam_size, vocab):\n",
    "    complete_captions = []\n",
    "    captions_tree = [\n",
    "        [([vocab['sos']], 1)]\n",
    "    ]\n",
    "    for i in range(40):\n",
    "        caps_to_be_expanded = captions_tree[i]\n",
    "        for item in caps_to_be_expanded:\n",
    "            if item[0][-1] == vocab['eos']:\n",
    "                complete_captions.append(item)\n",
    "        caps_to_be_expanded = sorted(filter(lambda t: t[0][-1] != vocab['eos'], caps_to_be_expanded), key=lambda t: t[1])\n",
    "        caps_to_be_expanded = caps_to_be_expanded[-beam_size:]\n",
    "        candidates = []\n",
    "        if len(caps_to_be_expanded) == 0:\n",
    "            return\n",
    "        for caption, prob in caps_to_be_expanded:\n",
    "            output = model.predict([fv, pad(caption)], verbose=0)\n",
    "            # output = 2d array\n",
    "            next_words = np.argsort(output)[0][-beam_size:]\n",
    "            for word in next_words:\n",
    "                new_caption = caption + [word]\n",
    "                new_prob = (log(output[0][word])+prob)*(1/len(new_caption)**1)\n",
    "                candidates.append((new_caption, new_prob))\n",
    "        captions_tree.append(candidates)\n",
    "    return complete_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ba7ac844",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = beam_search(fv, model, 3, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "abec2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_list = [item for sublist in a for item in sublist]\n",
    "\n",
    "# Sort the flattened list by the second element of each tuple\n",
    "sorted_list = sorted(a, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "bb8650b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in his mouth . . . . . . . . . . . . . . . . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in the background . . . . . . . . . . . . . . . . . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in his hand . . . . . . . . . . . . . . . . . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in his mouth . . . . . . . . . . . . . . . . . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in the background . . . . . . . . . . . . . . . . . . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in his hand . . . . . . . . . . . . . . . . . . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in his mouth . . . . . . . . . . . . . . . . . . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in the background . . . . . . . . . . . . . . . . . . . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in his mouth . . . . . . . . . . . . . . . . . . . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in his hand . . . . . . . . . . . . . . . . . . . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a rock face . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with his arms . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with his head . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face face . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree face . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in his hand . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in his mouth . eos\n",
      "-6.580594631794981e-05\n",
      "\n",
      "sos a man in a red shirt is climbing a sheer cliff face with a large tree in the background . eos\n",
      "-6.580594631794981e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in sorted_list[-20:]:\n",
    "    print(decode_caption(item[0]))\n",
    "    print(final_cap[1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a847ed",
   "metadata": {},
   "source": [
    "BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43879d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu, sentence_bleu\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8a6f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_dict = np.load(\"30k/captions_dict.npy\", allow_pickle=True).item()\n",
    "model = keras.models.load_model('models/image_caption_gen_v1.h5')\n",
    "filenames_test = np.load(\"30k/filenames_testing.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(filepath, captions_dict, model):\n",
    "    ref = []\n",
    "    for item in captions_dict[filepath.split(\"\\\\\")[1]]:\n",
    "        ref.append(item.split()[1:-1])\n",
    "    cand = decode_caption(generate_caption(generate_img_feature_vector(filepath))).split()[1:-1]\n",
    "    return np.array((sentence_bleu(ref, cand, weights=(1.0, 0, 0, 0)), \n",
    "    sentence_bleu(ref, cand, weights=(0.5, 0.5, 0, 0)),\n",
    "    sentence_bleu(ref, cand, weights=(0.3, 0.3, 0.3, 0)),\n",
    "    sentence_bleu(ref, cand, weights=(0.25, 0.25, 0.25, 0.25))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "n=0\n",
    "filenames_test = list(filenames_test)[:500]\n",
    "for item in filenames_test:\n",
    "    filepath = \"Flickr_Data/Images\\\\\"+item\n",
    "    result = compute_bleu(filepath, captions_dict, model)\n",
    "    scores.append(result)\n",
    "    print(n)\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18ce7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bleu = np.array(scores).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60182ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cb292a",
   "metadata": {},
   "source": [
    "Top-k Sampling and Nucleus Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520c20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "import random\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658e6f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_temp(softmax, temperature):\n",
    "    softmax = np.log(softmax) / temperature\n",
    "    softmax = np.exp(softmax)\n",
    "    softmax = softmax / np.sum(softmax)\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a041d057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k(softmax, k, temp):\n",
    "    x = np.argsort(softmax)\n",
    "    for item in x[:-k]:\n",
    "        softmax[item] = 0\n",
    "    softmax = normalize([softmax], norm='l1')[0]\n",
    "    softmax = apply_temp(softmax, temp)\n",
    "    next_word = random.choices(list(range(0, len(softmax))), weights = softmax, k=1)[0]\n",
    "    \n",
    "    return next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102d954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption_top_k(img_feature_vector):\n",
    "    caption = [1]\n",
    "    next_word = None\n",
    "    \n",
    "    while next_word != vocab['eos'] and len(caption) != 40:\n",
    "        output = model.predict([img_feature_vector, pad(caption)], verbose=0)\n",
    "        \n",
    "        next_word = top_k(output[0], 10, 0.5)\n",
    "        \n",
    "        caption.append(next_word)\n",
    "        \n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nucleus_sampling(softmax, p, temp):\n",
    "    actual_p = 0\n",
    "    x = np.argsort(softmax)\n",
    "    for item in x[::-1]:\n",
    "        if actual_p < p:\n",
    "            actual_p = actual_p+softmax[item]\n",
    "        else:\n",
    "            softmax[item] = 0\n",
    "    softmax = normalize([softmax], norm='l1')[0]\n",
    "    softmax = apply_temp(softmax, temp)\n",
    "    next_word = random.choices(list(range(0, len(softmax))), weights = softmax, k=1)[0]\n",
    "    \n",
    "    return next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb35e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption_nucleus_sampling(img_feature_vector):\n",
    "    caption = [1]\n",
    "    next_word = None\n",
    "\n",
    "    while next_word != vocab['eos'] and len(caption) != 40:\n",
    "        output = model.predict([img_feature_vector, pad(caption)], verbose=0)\n",
    "\n",
    "        next_word = nucleus_sampling(output[0], 0.9, 0.5)\n",
    "\n",
    "        caption.append(next_word)\n",
    "\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_caption_generator_top_k(filepath, model):\n",
    "    if type(filepath) == int:\n",
    "        filepath = images[filepath]\n",
    "    return decode_caption(generate_caption_top_k(generate_img_feature_vector(filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43a60b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_caption_generator_nucleus_sampling(filepath, model):\n",
    "    if type(filepath) == int:\n",
    "        filepath = images[filepath]\n",
    "    return decode_caption(generate_caption_nucleus_sampling(generate_img_feature_vector(filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f495ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(8009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f201587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_caption_generator_nucleus_sampling(8009, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc59d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bac60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "references = [[['this', 'is', 'a', 'test'], ['this', 'is' 'test']], [['hello', 'there'], ['hi', 'there']]]\n",
    "candidates = [['this', 'is', 'a', 'test'], ['hello', 'there']]\n",
    "score = corpus_bleu(references, candidates)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a0f2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b06f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37eb94c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the dog \\'s are running !across the dark # \" hello \" sky. a dog and a dog'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '''the dog 's are , running !across the dark . # \" hello \" sky. a dog & a dog'''\n",
    "x = x.split()\n",
    "y = x[:]\n",
    "for i, item in enumerate(y):\n",
    "    if item in string.punctuation:\n",
    "        if item == '&':\n",
    "            x[i] = \"and\"\n",
    "        elif item == '\"':\n",
    "            pass\n",
    "        elif item == \"#\":\n",
    "            pass\n",
    "        else:\n",
    "            x[i] = None \n",
    "\n",
    "z = []\n",
    "for item in x:\n",
    "    if item != None:\n",
    "        z.append(item)\n",
    "\" \".join(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
